{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b039339",
   "metadata": {},
   "source": [
    "# Building the Clean Modeling Dataset (`df_clean`)\n",
    "\n",
    "This notebook consolidates the enriched NBA dataset into a single,\n",
    "leakage-free, model-ready table.\n",
    "\n",
    "All feature cleaning, target construction, and temporal alignment\n",
    "are performed here. No modeling assumptions are made at this stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a6e0927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: c:\\Users\\Luc\\Documents\\projets-data\\nba-awards-predictor\n",
      "DATA_PROCESSED: c:\\Users\\Luc\\Documents\\projets-data\\nba-awards-predictor\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "# ------------------------------------------------------------------\n",
    "# Project root (robust, no pyproject.toml needed)\n",
    "# Looks for common \"project markers\": .git, data/, notebooks/, README.md\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR\n",
    "\n",
    "MARKERS = [\n",
    "    \".git\",\n",
    "    \"data\",\n",
    "    \"notebooks\",\n",
    "    \"README.md\",\n",
    "]\n",
    "\n",
    "def is_project_root(p: Path) -> bool:\n",
    "    return any((p / m).exists() for m in MARKERS)\n",
    "\n",
    "while not is_project_root(PROJECT_ROOT):\n",
    "    if PROJECT_ROOT.parent == PROJECT_ROOT:\n",
    "        raise RuntimeError(\n",
    "            \"Project root not found. Run this notebook from inside the repo \"\n",
    "            \"(a folder containing one of: .git, data/, notebooks/, README.md).\"\n",
    "        )\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "DATA_RAW = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "DATA_PROCESSED_FINAL = DATA_PROCESSED / \"players\" / \"final\"\n",
    "DATA_INTERIM = PROJECT_ROOT / \"data\" / \"interim\"\n",
    "DATA_INTERIM.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"DATA_PROCESSED:\", DATA_PROCESSED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe487967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape: (13843, 436)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>Player</th>\n",
       "      <th>Age</th>\n",
       "      <th>Team</th>\n",
       "      <th>Pos</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>...</th>\n",
       "      <th>raptor__o_raptor_rank</th>\n",
       "      <th>raptor__player_id</th>\n",
       "      <th>raptor__player_name</th>\n",
       "      <th>raptor__poss</th>\n",
       "      <th>raptor__raptor_defense</th>\n",
       "      <th>raptor__raptor_offense</th>\n",
       "      <th>raptor__raptor_rank</th>\n",
       "      <th>raptor__raptor_total</th>\n",
       "      <th>raptor__season</th>\n",
       "      <th>raptor__war_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199.0</td>\n",
       "      <td>A 1/2an Tabak</td>\n",
       "      <td>25.0</td>\n",
       "      <td>TOR</td>\n",
       "      <td>C</td>\n",
       "      <td>67.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139.0</td>\n",
       "      <td>A arA&lt;&lt;nas MarAiulionis</td>\n",
       "      <td>31.0</td>\n",
       "      <td>SAC</td>\n",
       "      <td>SG</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202.0</td>\n",
       "      <td>A.C. Green</td>\n",
       "      <td>32.0</td>\n",
       "      <td>PHO</td>\n",
       "      <td>SF</td>\n",
       "      <td>82.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>...</td>\n",
       "      <td>155.0</td>\n",
       "      <td>greenac01</td>\n",
       "      <td>A.C. Green</td>\n",
       "      <td>4316.0</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>174.0</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1.648381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 436 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rk                   Player   Age Team Pos     G    GS    MP   FG  FGA  \\\n",
       "0  199.0            A 1/2an Tabak  25.0  TOR   C  67.0  18.0  19.9  3.4  6.2   \n",
       "1  139.0  A arA<<nas MarAiulionis  31.0  SAC  SG  53.0   0.0  19.6  3.3  7.3   \n",
       "2  202.0               A.C. Green  32.0  PHO  SF  82.0  36.0  25.8  2.6  5.4   \n",
       "\n",
       "   ...  raptor__o_raptor_rank  raptor__player_id  raptor__player_name  \\\n",
       "0  ...                    NaN               None                 None   \n",
       "1  ...                    NaN               None                 None   \n",
       "2  ...                  155.0          greenac01           A.C. Green   \n",
       "\n",
       "   raptor__poss  raptor__raptor_defense  raptor__raptor_offense  \\\n",
       "0           NaN                     NaN                     NaN   \n",
       "1           NaN                     NaN                     NaN   \n",
       "2        4316.0                    -0.6                    -0.6   \n",
       "\n",
       "   raptor__raptor_rank  raptor__raptor_total  raptor__season  \\\n",
       "0                  NaN                   NaN             NaN   \n",
       "1                  NaN                   NaN             NaN   \n",
       "2                174.0                  -1.3          1996.0   \n",
       "\n",
       "   raptor__war_total  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2           1.648381  \n",
       "\n",
       "[3 rows x 436 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ENRICHED_PATH = DATA_PROCESSED_FINAL / \"all_years_enriched.parquet\"\n",
    "assert ENRICHED_PATH.exists(), f\"Missing file: {ENRICHED_PATH}\"\n",
    "\n",
    "df = pd.read_parquet(ENRICHED_PATH)\n",
    "print(\"Raw shape:\", df.shape)\n",
    "display(df.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6bd4e",
   "metadata": {},
   "source": [
    "## 1) Basic hygiene\n",
    "\n",
    "- Ensure `season` exists and has plausible range.\n",
    "- Ensure the dataset granularity is **one row per (player_key, season)**.\n",
    "- Drop known rare duplicates (keep the most complete row).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79a554cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seasons: 1996 → 2024 | n = 29\n",
      "Duplicate player-season rows: 2\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Basic structural checks\n",
    "# -----------------------------\n",
    "assert \"season\" in df.columns, \"Missing `season` column.\"\n",
    "print(\"Seasons:\", int(df[\"season\"].min()), \"→\", int(df[\"season\"].max()), \"| n =\", df[\"season\"].nunique())\n",
    "\n",
    "PLAYER_KEY = \"player_key\" if \"player_key\" in df.columns else \"Player\"\n",
    "assert PLAYER_KEY in df.columns, f\"Missing player identifier ({PLAYER_KEY}).\"\n",
    "\n",
    "dup_mask = df.duplicated(subset=[PLAYER_KEY, \"season\"], keep=False)\n",
    "n_dups = int(dup_mask.sum())\n",
    "print(\"Duplicate player-season rows:\", n_dups)\n",
    "\n",
    "if n_dups:\n",
    "    # keep row with max non-null count\n",
    "    df_dups = df.loc[dup_mask].copy()\n",
    "    df_dups[\"_nn\"] = df_dups.notna().sum(axis=1)\n",
    "    df_dups = df_dups.sort_values([PLAYER_KEY, \"season\", \"_nn\"], ascending=[True, True, False])\n",
    "\n",
    "    df_keep = df_dups.drop_duplicates(subset=[PLAYER_KEY, \"season\"], keep=\"first\").drop(columns=[\"_nn\"])\n",
    "    df_rest = df.loc[~dup_mask]\n",
    "    df = pd.concat([df_rest, df_keep], ignore_index=True)\n",
    "\n",
    "    # re-check\n",
    "    assert df.duplicated(subset=[PLAYER_KEY, \"season\"]).sum() == 0, \"Still have duplicates after cleanup.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697c7334",
   "metadata": {},
   "source": [
    "## 2) Minimal column cleanup\n",
    "\n",
    "We keep `df_clean` as the **analysis-ready table** (identifiers, a few categorical fields, plus numeric stats).  \n",
    "We remove:\n",
    "- obvious duplicates (e.g., duplicated age columns),\n",
    "- redundant year fields (keep `season`),\n",
    "- raw award strings / helper columns that are not used.\n",
    "\n",
    "> The **model-ready** matrices are built later from `df_clean` (in notebook 03).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8362bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 9 columns from df_clean\n",
      "df_clean shape: (13842, 427)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Column cleanup (project-specific)\n",
    "# -----------------------------\n",
    "DROP_FROM_DF_CLEAN = [\n",
    "    # redundant year field\n",
    "    \"year\",\n",
    "\n",
    "    # duplicate age/team fields from nba_api (kept: Age, Team)\n",
    "    \"AGE\", \"TEAM_ABBREVIATION\",\n",
    "\n",
    "    # award strings from different stat tables (not useful; keep binary winner labels separately)\n",
    "    \"tot_Awards\", \"p36_Awards\", \"p100_Awards\", \"adv_Awards\", \"adj_Awards\", \"shot_Awards\",\n",
    "]\n",
    "\n",
    "before = df.shape[1]\n",
    "df_clean = df.drop(columns=[c for c in DROP_FROM_DF_CLEAN if c in df.columns]).copy()\n",
    "print(f\"Dropped {before - df_clean.shape[1]} columns from df_clean\")\n",
    "print(\"df_clean shape:\", df_clean.shape)\n",
    "\n",
    "# sanity\n",
    "assert \"season\" in df_clean.columns\n",
    "assert \"Age\" in df_clean.columns\n",
    "assert \"Team\" in df_clean.columns\n",
    "assert \"year\" not in df_clean.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fee7b5c",
   "metadata": {},
   "source": [
    "## 3) Leakage columns (kept in df_clean, excluded from X)\n",
    "\n",
    "We keep award outcomes in `df_clean` for auditing and target construction, but we **never** include them in the feature matrix `X_df`.\n",
    "\n",
    "This makes the pipeline transparent:\n",
    "- `df_clean` contains *everything we know*\n",
    "- `X_df_*` contains *only allowable inputs*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dea5650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leakage-like columns found: 38\n",
      "['is_rookie', 'is_mvp', 'mvp_rank', 'is_dpoy', 'dpoy_rank', 'is_roy', 'roy_rank', 'is_mip', 'mip_rank', 'is_smoy', 'smoy_rank', 'is_cpoy', 'cpoy_rank', 'is_mvp_winner', 'is_dpoy_winner', 'is_roy_winner', 'is_mip_winner', 'is_smoy_winner', 'is_cpoy_winner', 'is_all_star', 'is_all_nba', 'all_nba_team', 'is_all_def', 'all_def_team', 'is_all_rookie', 'all_rookie_team', 'pct_is_mvp_winner', 'pct_is_dpoy_winner', 'pct_is_roy_winner', 'pct_is_mip_winner']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Quick leakage inventory (for visibility only)\n",
    "# -----------------------------\n",
    "import re\n",
    "\n",
    "LEAK_PATTERNS = [\n",
    "    r\".*_rank$\",\n",
    "    r\"^is_.*\",                      # includes is_*_winner\n",
    "    r\"^all_nba_.*\", r\"^all_def_.*\", r\"^all_rookie_.*\",\n",
    "    r\"^has_.*consideration$\",\n",
    "    r\"^pct_is_.*winner$\",\n",
    "    r\"^pct_is_.*_winner$\",\n",
    "]\n",
    "\n",
    "def is_leak_col(c: str) -> bool:\n",
    "    return any(re.match(p, c) for p in LEAK_PATTERNS)\n",
    "\n",
    "leak_cols = [c for c in df_clean.columns if is_leak_col(c)]\n",
    "print(\"Leakage-like columns found:\", len(leak_cols))\n",
    "print(leak_cols[:30])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e7b48",
   "metadata": {},
   "source": [
    "## 4) Save outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbc41bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Luc\\Documents\\projets-data\\nba-awards-predictor\\data\\interim\\df_clean.parquet\n",
      "Saved: c:\\Users\\Luc\\Documents\\projets-data\\nba-awards-predictor\\data\\interim\\df_clean_columns.csv\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Save df_clean + a quick column list for manual review\n",
    "# -----------------------------\n",
    "\n",
    "DF_CLEAN_PATH = DATA_INTERIM / \"df_clean.parquet\"\n",
    "COLS_PATH = DATA_INTERIM / \"df_clean_columns.csv\"\n",
    "\n",
    "df_clean.to_parquet(DF_CLEAN_PATH, index=False)\n",
    "pd.Series(df_clean.columns, name=\"column\").to_csv(COLS_PATH, index=False)\n",
    "\n",
    "print(\"Saved:\", DF_CLEAN_PATH)\n",
    "print(\"Saved:\", COLS_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba-awards",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
